{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e72b81-7001-419a-8fc8-e3dc0239ea3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ğŸ“Œ **1. Veri Ã–n Ä°ÅŸleme Fonksiyonu**\n",
    "def preprocess_data(file_path, is_train=True, scaler=None, encoder_dict=None):\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f\"âœ… Veri yÃ¼klendi: {df.shape}\")\n",
    "\n",
    "    # ğŸŸ¢ 1. Kategorik deÄŸiÅŸkenleri encode et\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    if is_train:\n",
    "        encoder_dict = {}\n",
    "        for col in categorical_cols:\n",
    "            le = LabelEncoder()\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "            encoder_dict[col] = le\n",
    "    else:\n",
    "        for col in categorical_cols:\n",
    "            if col in encoder_dict:\n",
    "                df[col] = df[col].map(lambda s: encoder_dict[col].transform([s])[0] if s in encoder_dict[col].classes_ else -1)\n",
    "\n",
    "    print(\"âœ… Kategorik deÄŸiÅŸkenler encode edildi!\")\n",
    "\n",
    "    # ğŸŸ¢ 2. Eksik deÄŸerleri doldur\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "    print(\"âœ… Eksik deÄŸerler dolduruldu!\")\n",
    "\n",
    "    # Hedef deÄŸiÅŸkeni ayÄ±r\n",
    "    y = df[\"rainfall\"] if \"rainfall\" in df.columns else None\n",
    "    X = df.drop(columns=[\"rainfall\"]) if \"rainfall\" in df.columns else df\n",
    "\n",
    "    # ğŸŸ¢ 3. SayÄ±sal deÄŸiÅŸkenleri Ã¶lÃ§eklendir\n",
    "    if is_train:\n",
    "        scaler = StandardScaler()\n",
    "        X = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X = scaler.transform(X)\n",
    "\n",
    "    print(\"âœ… SayÄ±sal deÄŸiÅŸkenler Ã¶lÃ§eklendirildi!\")\n",
    "    \n",
    "    return X, y, scaler, encoder_dict\n",
    "\n",
    "# ğŸ“Œ **2. XGBoost Model EÄŸitme Fonksiyonu**\n",
    "def train_xgboost(X, y):\n",
    "    \"\"\"\n",
    "    XGBoost Modeli ile eÄŸitimi gerÃ§ekleÅŸtirir.\n",
    "    \"\"\"\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_estimators=500,  # Daha yÃ¼ksek aÄŸaÃ§ sayÄ±sÄ±\n",
    "        learning_rate=0.01,  # KÃ¼Ã§Ã¼k adÄ±mlarla Ã¶ÄŸren\n",
    "        max_depth=6,  # Derinlik\n",
    "        colsample_bytree=0.8,  # Feature sampling\n",
    "        subsample=0.8,  # Veri alt Ã¶rnekleme\n",
    "        eval_metric=\"auc\",\n",
    "        use_label_encoder=False\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_val, y_val)], early_stopping_rounds=20, verbose=10)\n",
    "\n",
    "    y_pred = model.predict_proba(X_val)[:, 1]\n",
    "    auc_score = roc_auc_score(y_val, y_pred)\n",
    "\n",
    "    print(f\"âœ… XGBoost Modeli EÄŸitildi! ROC AUC: {auc_score:.4f}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# ğŸ“Œ **3. Test Verisi Ãœzerinde Tahmin Yapma Fonksiyonu**\n",
    "def predict_and_save(model, test_file, output_file, scaler, encoder_dict):\n",
    "    X_test, _, _, _ = preprocess_data(test_file, is_train=False, scaler=scaler, encoder_dict=encoder_dict)\n",
    "    \n",
    "    predictions = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Test seti ID'sini al\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    test_ids = test_df[\"id\"]\n",
    "\n",
    "    # Kaggle formatÄ±nda CSV oluÅŸtur\n",
    "    submission = pd.DataFrame({\"id\": test_ids, \"rainfall\": predictions})\n",
    "    submission.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"âœ… Tahminler {output_file} dosyasÄ±na kaydedildi!\")\n",
    "\n",
    "# ğŸ“Œ **4. Ã‡alÄ±ÅŸtÄ±rma Kodu**\n",
    "train_file = \"train.csv\"\n",
    "test_file = \"test.csv\"\n",
    "output_file = \"xgboost_submission.csv\"\n",
    "\n",
    "# 1ï¸âƒ£ Veriyi iÅŸle\n",
    "X_train, y_train, scaler, encoder_dict = preprocess_data(train_file, is_train=True)\n",
    "\n",
    "# 2ï¸âƒ£ Modeli eÄŸit (XGBoost kullanÄ±yoruz)\n",
    "xgb_model = train_xgboost(X_train, y_train)\n",
    "\n",
    "# 3ï¸âƒ£ Test verisi Ã¼zerinde tahmin yap ve sonucu kaydet\n",
    "predict_and_save(xgb_model, test_file, output_file, scaler, encoder_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
